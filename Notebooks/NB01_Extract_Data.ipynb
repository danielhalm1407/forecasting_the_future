{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2469734",
   "metadata": {},
   "source": [
    "# A Deeper Look Into Commodity Market Impacts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7c9713",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9b3d34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Web - Scraping and API Requests\n",
    "import requests\n",
    "\n",
    "\n",
    "# Data Manipulation and Analysis\n",
    "import pandas as pd\n",
    "from pprint import pprint \n",
    "import json\n",
    "\n",
    "# Database Connection\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# SQL Querying\n",
    "from sqlalchemy import inspect, text\n",
    "\n",
    "# File and System Operations\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac30ce4a",
   "metadata": {},
   "source": [
    "## Other Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4bee6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None) # Display all columns in any given DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1fc36f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This allows one to reload the custom package without having to install it again\n",
    "%load_ext autoreload "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33a3b5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this allows one to reload the custom package without having to install it again\n",
    "%autoreload 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e3f604",
   "metadata": {},
   "source": [
    "### Import Custom Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b391693d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the wd\n",
    "sys.path.insert(0,'../src/')\n",
    "\n",
    "#Import the packages\n",
    "from macro_utils import sql_queries as sqlq\n",
    "from macro_utils import functions as macro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca3f400",
   "metadata": {},
   "source": [
    "## Connect to the Database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa22f34",
   "metadata": {},
   "source": [
    "### Finding the correct file directory for the database credentials json with the api key and password\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e639ebaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.path.dirname(os.path.abspath(\"NB01_Extract_Data.ipynb\"))\n",
    "sys.path.insert(0,os.path.join(current_dir, '..'))\n",
    "\n",
    "credentials_file_path = os.path.join(current_dir, '..', \"supabase_credentials.json\")\n",
    "\n",
    "# open the  credentials file and load the data into a variable\n",
    "with open(credentials_file_path, \"r\") as f:\n",
    "    credentials = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef9956d",
   "metadata": {},
   "source": [
    "#### Connect to the SupaBase Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5834ec46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to the database\n",
    "supabase_engine = sqlq.get_supabase_engine(\n",
    "    user=\"postgres\",\n",
    "    password=credentials['password'],\n",
    "    host=credentials['host'],\n",
    "    port=5432,\n",
    "    database=\"postgres\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c1b27f",
   "metadata": {},
   "source": [
    "### Create an Empty Table and Fill it with the Right Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54712f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop the table if we wish\n",
    "with supabase_engine.begin() as connection:\n",
    "    connection.execute(text(sqlq.DROP_TS_TABLE_SQL_QUERY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "047c8509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample DataFrame with 2 columns: 'yq' (year-quarter) and 'level'\n",
    "test_data = pd.DataFrame({\n",
    "    'yq': ['2023Q1', '2023Q2', '2023Q3', '2023Q4', '2024Q1'],\n",
    "    'level': [100, 110, 105, 115, 120]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7cacd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Execute the CREATE TABLE query to create a blank table if it doesn't already exist\n",
    "with supabase_engine.begin() as connection:\n",
    "    connection.execute(text(sqlq.CREATE_TS_TABLE_SQL_QUERY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2702bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "## find the ids (in this case dates) that already exist\n",
    "with supabase_engine.connect() as conn:\n",
    "    existing_ids = conn.execute(text(\"SELECT yq FROM ts_data\")).fetchall()\n",
    "## filter out only the ids that will be unique to the existing table\n",
    "existing_ids = {row[0] for row in existing_ids}\n",
    "new_rows = test_data[~test_data['yq'].isin(existing_ids)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbe109ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in the data into the table\n",
    "sqlq.make_table(new_rows, \"ts_data\", supabase_engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f52ebce",
   "metadata": {},
   "source": [
    "### Test if Can be Read Back In Properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7cad5c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yq</th>\n",
       "      <th>level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023Q1</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023Q2</td>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023Q3</td>\n",
       "      <td>105.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023Q4</td>\n",
       "      <td>115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024Q1</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       yq  level\n",
       "0  2023Q1  100.0\n",
       "1  2023Q2  110.0\n",
       "2  2023Q3  105.0\n",
       "3  2023Q4  115.0\n",
       "4  2024Q1  120.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with supabase_engine.connect() as connection:\n",
    "    test = pd.read_sql(text(sqlq.GET_TS_DATA_SQL_QUERY), connection)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848f5058",
   "metadata": {},
   "source": [
    "## Create and use a Function to Dynamically Create a SQL Table\n",
    "\n",
    "This should automatically detect the columns and types of the data and create a table with the correct column names and types, with only as much data capacity as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b95cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('CREATE TABLE IF NOT EXISTS test_data (\\n'\n",
      " '    yq VARCHAR(6),\\n'\n",
      " '    level INTEGER\\n'\n",
      " ');')\n"
     ]
    }
   ],
   "source": [
    "def infer_sql_type(series) -> str:\n",
    "    \"\"\"\n",
    "    Infers the appropriate SQL data type for a pandas Series.\n",
    "\n",
    "    Args:\n",
    "        series: pd.Series\n",
    "            The pandas Series for which to infer the SQL type.\n",
    "\n",
    "    Returns:\n",
    "        str: The inferred SQL data type as a string.\n",
    "    \"\"\"\n",
    "    # Check if the series is of integer type\n",
    "    if pd.api.types.is_integer_dtype(series):\n",
    "        return \"INTEGER\"\n",
    "    # Check if the series is of float type\n",
    "    elif pd.api.types.is_float_dtype(series):\n",
    "        return \"REAL\"\n",
    "    # Check if the series is of boolean type\n",
    "    elif pd.api.types.is_bool_dtype(series):\n",
    "        return \"BOOLEAN\"\n",
    "    # Check if the series is of datetime type\n",
    "    elif pd.api.types.is_datetime64_any_dtype(series):\n",
    "        return \"TIMESTAMP\"\n",
    "    else:\n",
    "        # For object types, infer VARCHAR length or fallback to TEXT\n",
    "        max_len = series.dropna().astype(str).map(len).max()\n",
    "        return f\"VARCHAR({max_len})\" if max_len else \"TEXT\"\n",
    "\n",
    "def df_to_create_table_sql(df: pd.DataFrame, table_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Generates a SQL CREATE TABLE statement based on the columns and types of a pandas DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df: pd.DataFrame\n",
    "            The DataFrame to analyze.\n",
    "        table_name: str\n",
    "            The name of the SQL table to create.\n",
    "\n",
    "    Returns:\n",
    "        str: The SQL CREATE TABLE statement as a string.\n",
    "    \"\"\"\n",
    "    cols = []\n",
    "    # Iterate through each column to infer its SQL type and build column definitions\n",
    "    for col in df.columns:\n",
    "        sql_type = infer_sql_type(df[col])\n",
    "        cols.append(f\"{col} {sql_type}\")\n",
    "    # Join all column definitions into a single string\n",
    "    col_definitions = \",\\n    \".join(cols)\n",
    "    # Format the final CREATE TABLE SQL statement\n",
    "    return f\"CREATE TABLE IF NOT EXISTS {table_name} (\\n    {col_definitions}\\n);\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d0adcf",
   "metadata": {},
   "source": [
    "### Use this Function to Create the Table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2e67d423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CREATE TABLE IF NOT EXISTS test_data (\\n    yq VARCHAR(6),\\n    level INTEGER\\n);'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CREATE_TABLE_SQL_QUERY = df_to_create_table_sql(test_data, \"test_data\")\n",
    "CREATE_TABLE_SQL_QUERY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0dc1c36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Execute the CREATE TABLE query to create a blank table if it doesn't already exist\n",
    "with supabase_engine.begin() as connection:\n",
    "    connection.execute(text(CREATE_TABLE_SQL_QUERY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7e1feec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in the data into the table\n",
    "sqlq.make_table(new_rows, \"test_data\", supabase_engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a353e49",
   "metadata": {},
   "source": [
    "## Analyse the Data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-macro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
